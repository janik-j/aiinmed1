{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LTHX4hS3nzQ"
      },
      "source": [
        "# This is a part of the **practical exercise** on uncertainty for dermatoscopy classification. Your task is to go through this tutorial and fill in missing code and answer the questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3Oa61UyBU6P"
      },
      "source": [
        "---\n",
        "\n",
        "First, as usual, we load needed libraries.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qubxee7lkY5X"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18\n",
        "from tqdm import tqdm\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBdqvv1NkzoF",
        "outputId": "633a8514-2515-4b53-983b-b6898a074054"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting medmnist\n",
            "  Downloading medmnist-2.2.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.19.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.66.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (9.4.0)\n",
            "Collecting fire (from medmnist)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.16.0+cu121)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2023.12.9)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (23.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->medmnist) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->medmnist) (1.3.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=99bb98bd3fcb4557921f192d4b285e3c72a097aa3036f6cce64bbc28aa84a115\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, medmnist\n",
            "Successfully installed fire-0.5.0 medmnist-2.2.3\n"
          ]
        }
      ],
      "source": [
        "! pip install medmnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGJMX6w_5qFW"
      },
      "source": [
        "---\n",
        "\n",
        "Now, let's load the dermatoscopy dataset from MedMNIST.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zar0upWnk98K",
        "outputId": "5699511d-d24b-4e75-9c8c-61e9b238f788"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://zenodo.org/records/6496656/files/dermamnist.npz to /root/.medmnist/dermamnist.npz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19725078/19725078 [00:01<00:00, 10203918.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/dermamnist.npz\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Dataset DermaMNIST (dermamnist)\n",
              "    Number of datapoints: 7007\n",
              "    Root location: /root/.medmnist\n",
              "    Split: train\n",
              "    Task: multi-class\n",
              "    Number of channels: 3\n",
              "    Meaning of labels: {'0': 'actinic keratoses and intraepithelial carcinoma', '1': 'basal cell carcinoma', '2': 'benign keratosis-like lesions', '3': 'dermatofibroma', '4': 'melanoma', '5': 'melanocytic nevi', '6': 'vascular lesions'}\n",
              "    Number of samples: {'train': 7007, 'val': 1003, 'test': 2005}\n",
              "    Description: The DermaMNIST is based on the HAM10000, a large collection of multi-source dermatoscopic images of common pigmented skin lesions. The dataset consists of 10,015 dermatoscopic images categorized as 7 different diseases, formulized as a multi-class classification task. We split the images into training, validation and test set with a ratio of 7:1:2. The source images of 3×600×450 are resized into 3×28×28.\n",
              "    License: CC BY-NC 4.0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "\n",
        "# preprocessing\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# load the data\n",
        "data_flag = 'dermamnist'\n",
        "info = INFO[data_flag]\n",
        "n_classes = len(info['label'])\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "train_set = DataClass(split='train', transform=data_transform, download=True)\n",
        "test_set = DataClass(split='test', transform=data_transform, download=True)\n",
        "train_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFHXLcot56-a"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "**Q1:** Next, we define objects of *DataLoader* class for training and testing splits. And we also define our model. Here it gets more challenging.\n",
        "\n",
        "In the cell below you need to:\n",
        "\n",
        "- load a resnet18 pretrained on ImageNet network from PyTorch\n",
        "- add a Dropout layer to the last fully-connected layer with 25% probability of neurons to be zeroed\n",
        "- change the last layer of the resnet18 such that it outputs 7 classes (the number of classes in the dermatoscopy dataset) instead of 1000 classes (as it is in the pretrained network)\n",
        "- freeze all the layers except the last one, as we are gonna fine tune in the next step our pretrained network on the medical dataset\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_05juRp5lEom"
      },
      "outputs": [],
      "source": [
        "train_batch_size = 40\n",
        "test_batch_size = 3\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_set,\n",
        "    batch_size=train_batch_size,\n",
        "    num_workers=1,\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_set,\n",
        "    batch_size=test_batch_size,\n",
        "    num_workers=1,\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "# # PUT YOUR CODE HERE\n",
        "from torchvision import models\n",
        "# load model\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Add dropout to the classifier\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(model.fc.in_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.25),  # Dropout layer with 25% chance of zeroing neurons\n",
        "    nn.Linear(512, n_classes)  # Output layer -> 7\n",
        ")\n",
        "\n",
        "# Freeze all layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the classifier (fc layer)\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RprcS-JGd2E"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Hope you made it work! Now we are gonna fine-tune the model (the last layer of it to be more precise).  \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "MJBLLVhMmlgV",
        "outputId": "d30906dd-7a44-4be5-923f-fabdb68565ea"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-28ae0f4ace04>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss = []\n",
        "model.train()\n",
        "\n",
        "for epoch in range(5):  # loop over the dataset 5 times to fine-tune the last layer\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(tqdm(train_loader), 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "print('\\n Finished training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38SCADFblYrH"
      },
      "source": [
        "**Q2:** What the heck? We got an error (`RuntimeError: 0D or 1D target tensor expected, multi-target not supported`).\n",
        "\n",
        "Any idea how we can fix it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj67xxx8tVn3"
      },
      "source": [
        "---\n",
        "\n",
        "Let's test the classification accuracy of our model.\n",
        "\n",
        "**Q3:** Please fill in the missing code below. You need to loop over the test set and compute how many times the trained network predicts the class\n",
        "correctly.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYJncy-AtT-A",
        "outputId": "2f179ef0-665e-44b2-8d87-ce496d38152b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 669/669 [00:14<00:00, 47.15it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.6982543640897756"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#  set model state to eval() for running the inference\n",
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "correcti = 0\n",
        "totali = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for images, labels in tqdm(test_loader):\n",
        "\n",
        "# # PUT YOUR CODE HERE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efSogAwOvzSQ"
      },
      "source": [
        "---\n",
        "\n",
        "The accuracy is ok, but not mindblowing. Thus it would be useful, as discussed in the lecture, to know how confident our model is. Let's use Monte Carlo dropout to find out. We now run 1000 forward passes and look at the distribution of the predictions.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBKchRQ62KhQ"
      },
      "outputs": [],
      "source": [
        "samples = 1000\n",
        "preds = []\n",
        "image = next(iter(test_loader))\n",
        "\n",
        "# compute predictions from our model with dropout\n",
        "for idx in range(samples):\n",
        "    preds.append(model(image[0]).clone().detach().numpy())\n",
        "preds = np.array(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOzEQSpa_J4k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bn-jeICxhgPS"
      },
      "outputs": [],
      "source": [
        "pred_class = []\n",
        "for idx in range(preds.shape[0]):\n",
        "    pred_class.append(np.argmax(preds[idx],1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPZdDm8b0lZV"
      },
      "source": [
        "---\n",
        "\n",
        "Now, we look at the results.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ABnDjFdinrg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n, bins, patches = plt.hist([x[0] for x in pred_class], facecolor='b', width = 0.4)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Counts')\n",
        "plt.xlim([0,8])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEcUdG1vipxT"
      },
      "outputs": [],
      "source": [
        "n, bins, patches = plt.hist([x[1] for x in pred_class], facecolor='b', width = 0.4)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Counts')\n",
        "plt.xlim([0,8])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Y0wFbXGQM_m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8S2FTwXYmycX"
      },
      "outputs": [],
      "source": [
        "n, bins, patches = plt.hist([x[2] for x in pred_class], facecolor='b', width = 0.4)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Counts')\n",
        "plt.xlim([0,8])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxgAawCH0pnh"
      },
      "source": [
        "---\n",
        "\n",
        "Hmm... each time, we predicted the same class 1000 times, but we expected the dropout to provide some distribution of predictions. Suspicuous...\n",
        "\n",
        "**Q4:** Is there a catch? Please write your thoughts on why we do not see a distribution and whether we could fix it somehow.\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
